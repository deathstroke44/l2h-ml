dataset:  movielens
NOTE: fast_kmeans and itq options share the same value
NOTE: fast_kmeans not enabled
Reach here
chunk  0
reach here 3
in write knn graph
weighted_n_edges  1067700
edge_set len 857387
written to  /data/kabir/similarity-search/models/lth-data/movielens-0-knn.graph
Namespace(n_clusters=256, kahip_config='strong', parts_path_root='path_to_data_directory/partition/', dsnode_path='path_to_data_directory/train_dsnode', k=100, k_graph=100, subsample=1, nn_mult=5, graph_file='movielens-0-knn.graph', dataset_name='movielens', fast_kmeans=False, itq=False, cplsh=True, pca=False, st=False, rp=False, kmeans_use_kahip_height=-2, compute_gt_nn=False, write_res=True, normalize_data=False, max_bin_count=70, acc_thresh=0.95, n_repeat_km=3, n_input=128, n_hidden=512, n_class=256, n_epochs=1, lr=0.0008, glove=False, sift=True, glove_c=False, sift_c=False, prefix10m=False, level2action={0: 'train'}, data_dir='/data/kabir/similarity-search/models/lth-data')
n_cluster 2
Configs: Namespace(n_clusters=2, kahip_config='strong', parts_path_root='path_to_data_directory/partition/', dsnode_path='path_to_data_directory/train_dsnode', k=100, k_graph=100, subsample=1, nn_mult=5, graph_file='movielens-0-knn.graph', dataset_name='movielens', fast_kmeans=False, itq=False, cplsh=True, pca=False, st=False, rp=False, kmeans_use_kahip_height=-2, compute_gt_nn=False, write_res=True, normalize_data=False, max_bin_count=70, acc_thresh=0.95, n_repeat_km=3, n_input=128, n_hidden=512, n_class=2, n_epochs=1, lr=0.0008, glove=False, sift=True, glove_c=False, sift_c=False, prefix10m=False, level2action={0: 'train'}, data_dir='/data/kabir/similarity-search/models/lth-data') 
 Starting data processing and training ...
torch.Size([10677]) height: 1 level2action {0: 'train'}
Namespace(n_clusters=2, kahip_config='strong', parts_path_root='path_to_data_directory/partition/', dsnode_path='path_to_data_directory/train_dsnode', k=100, k_graph=100, subsample=1, nn_mult=5, graph_file='movielens-0-knn.graph', dataset_name='movielens', fast_kmeans=False, itq=False, cplsh=True, pca=False, st=False, rp=False, kmeans_use_kahip_height=-2, compute_gt_nn=False, write_res=True, normalize_data=False, max_bin_count=70, acc_thresh=0.95, n_repeat_km=3, n_input=128, n_hidden=512, n_class=2, n_epochs=1, lr=0.0008, glove=False, sift=True, glove_c=False, sift_c=False, prefix10m=False, level2action={0: 'train'}, data_dir='/data/kabir/similarity-search/models/lth-data')
/data/kabir/similarity-search/models/lth-data/movielens-0-knn.graph
/home/kabir/KaHIP/deploy/kaffpa /data/kabir/similarity-search/models/lth-data/movielens-0-knn.graph --preconfiguration=strong --output_filename=path_to_data_directory/partition/2movielens0ht1_100_100 --k=2
Done partitioning top level!
An error occurred: [Errno 2] No such file or directory: 'path_to_data_directory/partition/2movielens0ht1_100_100' movielens
dataset:  netflix
NOTE: fast_kmeans and itq options share the same value
NOTE: fast_kmeans not enabled
Reach here
chunk  0
reach here 3
in write knn graph
weighted_n_edges  1777000
edge_set len 1320981
written to  /data/kabir/similarity-search/models/lth-data/netflix-0-knn.graph
Namespace(n_clusters=256, kahip_config='strong', parts_path_root='path_to_data_directory/partition/', dsnode_path='path_to_data_directory/train_dsnode', k=100, k_graph=100, subsample=1, nn_mult=5, graph_file='netflix-0-knn.graph', dataset_name='netflix', fast_kmeans=False, itq=False, cplsh=True, pca=False, st=False, rp=False, kmeans_use_kahip_height=-2, compute_gt_nn=False, write_res=True, normalize_data=False, max_bin_count=70, acc_thresh=0.95, n_repeat_km=3, n_input=128, n_hidden=512, n_class=256, n_epochs=1, lr=0.0008, glove=False, sift=True, glove_c=False, sift_c=False, prefix10m=False, level2action={0: 'train'}, data_dir='/data/kabir/similarity-search/models/lth-data')
n_cluster 2
Configs: Namespace(n_clusters=2, kahip_config='strong', parts_path_root='path_to_data_directory/partition/', dsnode_path='path_to_data_directory/train_dsnode', k=100, k_graph=100, subsample=1, nn_mult=5, graph_file='netflix-0-knn.graph', dataset_name='netflix', fast_kmeans=False, itq=False, cplsh=True, pca=False, st=False, rp=False, kmeans_use_kahip_height=-2, compute_gt_nn=False, write_res=True, normalize_data=False, max_bin_count=70, acc_thresh=0.95, n_repeat_km=3, n_input=128, n_hidden=512, n_class=2, n_epochs=1, lr=0.0008, glove=False, sift=True, glove_c=False, sift_c=False, prefix10m=False, level2action={0: 'train'}, data_dir='/data/kabir/similarity-search/models/lth-data') 
 Starting data processing and training ...
torch.Size([17770]) height: 1 level2action {0: 'train'}
Namespace(n_clusters=2, kahip_config='strong', parts_path_root='path_to_data_directory/partition/', dsnode_path='path_to_data_directory/train_dsnode', k=100, k_graph=100, subsample=1, nn_mult=5, graph_file='netflix-0-knn.graph', dataset_name='netflix', fast_kmeans=False, itq=False, cplsh=True, pca=False, st=False, rp=False, kmeans_use_kahip_height=-2, compute_gt_nn=False, write_res=True, normalize_data=False, max_bin_count=70, acc_thresh=0.95, n_repeat_km=3, n_input=128, n_hidden=512, n_class=2, n_epochs=1, lr=0.0008, glove=False, sift=True, glove_c=False, sift_c=False, prefix10m=False, level2action={0: 'train'}, data_dir='/data/kabir/similarity-search/models/lth-data')
/data/kabir/similarity-search/models/lth-data/netflix-0-knn.graph
/home/kabir/KaHIP/deploy/kaffpa /data/kabir/similarity-search/models/lth-data/netflix-0-knn.graph --preconfiguration=strong --output_filename=path_to_data_directory/partition/2netflix0ht1_100_100 --k=2
Done partitioning top level!
chunk  0
An error occurred: mat1 and mat2 shapes cannot be multiplied (64x300 and 128x512) netflix
dataset:  sun
NOTE: fast_kmeans and itq options share the same value
NOTE: fast_kmeans not enabled
Reach here
chunk  0
reach here 3
in write knn graph
weighted_n_edges  1582120
edge_set len 1447621
written to  /data/kabir/similarity-search/models/lth-data/sun-0-knn.graph
Namespace(n_clusters=256, kahip_config='strong', parts_path_root='path_to_data_directory/partition/', dsnode_path='path_to_data_directory/train_dsnode', k=20, k_graph=100, subsample=1, nn_mult=5, graph_file='sun-0-knn.graph', dataset_name='sun', fast_kmeans=False, itq=False, cplsh=True, pca=False, st=False, rp=False, kmeans_use_kahip_height=-2, compute_gt_nn=False, write_res=True, normalize_data=False, max_bin_count=70, acc_thresh=0.95, n_repeat_km=3, n_input=128, n_hidden=512, n_class=256, n_epochs=1, lr=0.0008, glove=False, sift=True, glove_c=False, sift_c=False, prefix10m=False, level2action={0: 'train'}, data_dir='/data/kabir/similarity-search/models/lth-data')
n_cluster 2
Configs: Namespace(n_clusters=2, kahip_config='strong', parts_path_root='path_to_data_directory/partition/', dsnode_path='path_to_data_directory/train_dsnode', k=20, k_graph=100, subsample=1, nn_mult=5, graph_file='sun-0-knn.graph', dataset_name='sun', fast_kmeans=False, itq=False, cplsh=True, pca=False, st=False, rp=False, kmeans_use_kahip_height=-2, compute_gt_nn=False, write_res=True, normalize_data=False, max_bin_count=70, acc_thresh=0.95, n_repeat_km=3, n_input=128, n_hidden=512, n_class=2, n_epochs=1, lr=0.0008, glove=False, sift=True, glove_c=False, sift_c=False, prefix10m=False, level2action={0: 'train'}, data_dir='/data/kabir/similarity-search/models/lth-data') 
 Starting data processing and training ...
torch.Size([79106]) height: 1 level2action {0: 'train'}
Namespace(n_clusters=2, kahip_config='strong', parts_path_root='path_to_data_directory/partition/', dsnode_path='path_to_data_directory/train_dsnode', k=20, k_graph=100, subsample=1, nn_mult=5, graph_file='sun-0-knn.graph', dataset_name='sun', fast_kmeans=False, itq=False, cplsh=True, pca=False, st=False, rp=False, kmeans_use_kahip_height=-2, compute_gt_nn=False, write_res=True, normalize_data=False, max_bin_count=70, acc_thresh=0.95, n_repeat_km=3, n_input=128, n_hidden=512, n_class=2, n_epochs=1, lr=0.0008, glove=False, sift=True, glove_c=False, sift_c=False, prefix10m=False, level2action={0: 'train'}, data_dir='/data/kabir/similarity-search/models/lth-data')
/data/kabir/similarity-search/models/lth-data/sun-0-knn.graph
/home/kabir/KaHIP/deploy/kaffpa /data/kabir/similarity-search/models/lth-data/sun-0-knn.graph --preconfiguration=strong --output_filename=path_to_data_directory/partition/2sun0ht1_100_20 --k=2
Done partitioning top level!
chunk  0
An error occurred: mat1 and mat2 shapes cannot be multiplied (64x512 and 128x512) sun
dataset:  Yelp
NOTE: fast_kmeans and itq options share the same value
NOTE: fast_kmeans not enabled
Reach here
chunk  0
reach here 3
in write knn graph
weighted_n_edges  7707900
edge_set len 5599153
written to  /data/kabir/similarity-search/models/lth-data/Yelp-0-knn.graph
Namespace(n_clusters=256, kahip_config='strong', parts_path_root='path_to_data_directory/partition/', dsnode_path='path_to_data_directory/train_dsnode', k=100, k_graph=100, subsample=1, nn_mult=5, graph_file='Yelp-0-knn.graph', dataset_name='Yelp', fast_kmeans=False, itq=False, cplsh=True, pca=False, st=False, rp=False, kmeans_use_kahip_height=-2, compute_gt_nn=False, write_res=True, normalize_data=False, max_bin_count=70, acc_thresh=0.95, n_repeat_km=3, n_input=128, n_hidden=512, n_class=256, n_epochs=1, lr=0.0008, glove=False, sift=True, glove_c=False, sift_c=False, prefix10m=False, level2action={0: 'train'}, data_dir='/data/kabir/similarity-search/models/lth-data')
n_cluster 2
Configs: Namespace(n_clusters=2, kahip_config='strong', parts_path_root='path_to_data_directory/partition/', dsnode_path='path_to_data_directory/train_dsnode', k=100, k_graph=100, subsample=1, nn_mult=5, graph_file='Yelp-0-knn.graph', dataset_name='Yelp', fast_kmeans=False, itq=False, cplsh=True, pca=False, st=False, rp=False, kmeans_use_kahip_height=-2, compute_gt_nn=False, write_res=True, normalize_data=False, max_bin_count=70, acc_thresh=0.95, n_repeat_km=3, n_input=128, n_hidden=512, n_class=2, n_epochs=1, lr=0.0008, glove=False, sift=True, glove_c=False, sift_c=False, prefix10m=False, level2action={0: 'train'}, data_dir='/data/kabir/similarity-search/models/lth-data') 
 Starting data processing and training ...
torch.Size([77079]) height: 1 level2action {0: 'train'}
Namespace(n_clusters=2, kahip_config='strong', parts_path_root='path_to_data_directory/partition/', dsnode_path='path_to_data_directory/train_dsnode', k=100, k_graph=100, subsample=1, nn_mult=5, graph_file='Yelp-0-knn.graph', dataset_name='Yelp', fast_kmeans=False, itq=False, cplsh=True, pca=False, st=False, rp=False, kmeans_use_kahip_height=-2, compute_gt_nn=False, write_res=True, normalize_data=False, max_bin_count=70, acc_thresh=0.95, n_repeat_km=3, n_input=128, n_hidden=512, n_class=2, n_epochs=1, lr=0.0008, glove=False, sift=True, glove_c=False, sift_c=False, prefix10m=False, level2action={0: 'train'}, data_dir='/data/kabir/similarity-search/models/lth-data')
/data/kabir/similarity-search/models/lth-data/Yelp-0-knn.graph
/home/kabir/KaHIP/deploy/kaffpa /data/kabir/similarity-search/models/lth-data/Yelp-0-knn.graph --preconfiguration=strong --output_filename=path_to_data_directory/partition/2Yelp0ht1_100_100 --k=2
Done partitioning top level!
An error occurred: [Errno 2] No such file or directory: 'path_to_data_directory/partition/2Yelp0ht1_100_100' Yelp
dataset:  yahoomusic
NOTE: fast_kmeans and itq options share the same value
NOTE: fast_kmeans not enabled
Reach here
chunk  0
reach here 3
in write knn graph
weighted_n_edges  13673600
edge_set len 9333584
written to  /data/kabir/similarity-search/models/lth-data/yahoomusic-0-knn.graph
Namespace(n_clusters=256, kahip_config='strong', parts_path_root='path_to_data_directory/partition/', dsnode_path='path_to_data_directory/train_dsnode', k=100, k_graph=100, subsample=1, nn_mult=5, graph_file='yahoomusic-0-knn.graph', dataset_name='yahoomusic', fast_kmeans=False, itq=False, cplsh=True, pca=False, st=False, rp=False, kmeans_use_kahip_height=-2, compute_gt_nn=False, write_res=True, normalize_data=False, max_bin_count=70, acc_thresh=0.95, n_repeat_km=3, n_input=128, n_hidden=512, n_class=256, n_epochs=1, lr=0.0008, glove=False, sift=True, glove_c=False, sift_c=False, prefix10m=False, level2action={0: 'train'}, data_dir='/data/kabir/similarity-search/models/lth-data')
n_cluster 2
Configs: Namespace(n_clusters=2, kahip_config='strong', parts_path_root='path_to_data_directory/partition/', dsnode_path='path_to_data_directory/train_dsnode', k=100, k_graph=100, subsample=1, nn_mult=5, graph_file='yahoomusic-0-knn.graph', dataset_name='yahoomusic', fast_kmeans=False, itq=False, cplsh=True, pca=False, st=False, rp=False, kmeans_use_kahip_height=-2, compute_gt_nn=False, write_res=True, normalize_data=False, max_bin_count=70, acc_thresh=0.95, n_repeat_km=3, n_input=128, n_hidden=512, n_class=2, n_epochs=1, lr=0.0008, glove=False, sift=True, glove_c=False, sift_c=False, prefix10m=False, level2action={0: 'train'}, data_dir='/data/kabir/similarity-search/models/lth-data') 
 Starting data processing and training ...
torch.Size([136736]) height: 1 level2action {0: 'train'}
Namespace(n_clusters=2, kahip_config='strong', parts_path_root='path_to_data_directory/partition/', dsnode_path='path_to_data_directory/train_dsnode', k=100, k_graph=100, subsample=1, nn_mult=5, graph_file='yahoomusic-0-knn.graph', dataset_name='yahoomusic', fast_kmeans=False, itq=False, cplsh=True, pca=False, st=False, rp=False, kmeans_use_kahip_height=-2, compute_gt_nn=False, write_res=True, normalize_data=False, max_bin_count=70, acc_thresh=0.95, n_repeat_km=3, n_input=128, n_hidden=512, n_class=2, n_epochs=1, lr=0.0008, glove=False, sift=True, glove_c=False, sift_c=False, prefix10m=False, level2action={0: 'train'}, data_dir='/data/kabir/similarity-search/models/lth-data')
/data/kabir/similarity-search/models/lth-data/yahoomusic-0-knn.graph
/home/kabir/KaHIP/deploy/kaffpa /data/kabir/similarity-search/models/lth-data/yahoomusic-0-knn.graph --preconfiguration=strong --output_filename=path_to_data_directory/partition/2yahoomusic0ht1_100_100 --k=2
Done partitioning top level!
chunk  0
An error occurred: mat1 and mat2 shapes cannot be multiplied (64x300 and 128x512) yahoomusic
